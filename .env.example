# LLM Werewolf - Environment Configuration
# Copy this file to .env and fill in your API keys
#
# IMPORTANT: This file stores API keys only.
# For configuring players and models, use players.yaml instead.
# See configs/players.yaml.example for detailed configuration options.

# ============================================================
# API Keys (Required for LLM providers)
# ============================================================

# OpenAI API Key
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (Claude models)
# Get your key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini API Key
# Get your key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# xAI API Key (Grok models)
# Get your key from: https://console.x.ai/
XAI_API_KEY=your_xai_api_key_here

# Deepseek API Key
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# ============================================================
# Usage Notes
# ============================================================
# 1. Only fill in API keys for providers you plan to use
# 2. Local models (Ollama, etc.) don't require API keys
# 3. Configure individual players in players.yaml:
#    - Copy players.yaml.example to players.yaml
#    - Specify model, base_url, and other settings per player
#    - Reference API keys using api_key_env field
# 4. Run with: uv run llm-werewolf --config players.yaml
